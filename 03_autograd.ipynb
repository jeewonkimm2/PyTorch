{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIg1iVbn2o+UB0mU77yR8m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gVKoFj8CErYP"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW0BSRdpE1d_",
        "outputId": "4431170a-5a95-4ffa-d377-341d19b3e39f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad = True -> Tracks all operations on the tensor\n",
        "x = torch.randn(3, requires_grad = True)\n",
        "y = x+2"
      ],
      "metadata": {
        "id": "PfJOR7iCE56y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0qsJEcVFDpN",
        "outputId": "01f29fae-f39c-4924-a379-1b28991ef70e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6531, -0.5831,  0.7873], requires_grad=True)\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "print(y.dtype)\n",
        "# grad_fn : references a Function tht has created the Tensor\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PY907HtFFSg",
        "outputId": "5308ba9a-3858-4a0b-93ce-3c3e7fc6276a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3469, 1.4169, 2.7873], grad_fn=<AddBackward0>)\n",
            "torch.float32\n",
            "<AddBackward0 object at 0x7f8cc75a1490>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWV2FYVgFN5K",
        "outputId": "0f684205-5209-4f47-c90c-adae10625559"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.4428,  6.0232, 23.3074], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEPM528oFcnW",
        "outputId": "1b7b2ade-5257-410e-89ef-87bfc924b5ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11.5911, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute."
      ],
      "metadata": {
        "id": "LIRNClYpFfbS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()"
      ],
      "metadata": {
        "id": "s6y9kMIGFpL0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dz/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjC8Wj4cFqZN",
        "outputId": "b9a7c287-82d6-4d3c-e9b9-4cad2d739920"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.6939, 2.8339, 5.5746])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward() \n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad = True)"
      ],
      "metadata": {
        "id": "chSgXlC9GrDF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x * 2\n",
        "\n",
        "for _ in range(10):\n",
        "  y = y*2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1vl1DD-GuvS",
        "outputId": "3015e797-27fe-43b6-d084-96000000f976"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2245.4829,  -544.1718,    21.6308], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([0.1,1.0,0.0001], dtype = torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "SRKnONvBHA82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2,2)\n",
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkoW2YkWHiUV",
        "outputId": "71786f1f-0850-4bec-a259-68e63b1e0907"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = ((a*3)/(a-1))\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2hehBGRHmaV",
        "outputId": "bc350afe-0d31-4d18-8642-aaf495f785bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApyRlhC7Htma",
        "outputId": "1060d0e6-d0cc-487c-c1e5-d9a60e88e716"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = (a*a).sum()\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X2CrCnBIIzE",
        "outputId": "e4d5f31b-b5af-4ce7-c7f2-2f6f96fb31d4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SumBackward0 object at 0x7f8ca6d0b400>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiN8xppJIUzL",
        "outputId": "ec592f82-312f-4d6b-81f0-4d183709ff1e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad = True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "  print((x**2).requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZx_C7_oIaZz",
        "outputId": "75f4eb3d-6480-4386-8d35-301b58445a90"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad = True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  # dummy example\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  # optimizing model(adjusting weights)\n",
        "  with torch.no_grad():\n",
        "    weights -= 0.1 * weights.grad\n",
        "  \n",
        "  weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCF_5JtlIfiy",
        "outputId": "684a6529-ac79-4cdc-9968-71cac91b25f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    }
  ]
}